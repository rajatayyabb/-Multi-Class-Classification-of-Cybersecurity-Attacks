{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12551473,"sourceType":"datasetVersion","datasetId":7919365}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-26T20:24:50.669613Z","iopub.execute_input":"2025-12-26T20:24:50.669992Z","iopub.status.idle":"2025-12-26T20:24:51.144134Z","shell.execute_reply.started":"2025-12-26T20:24:50.669959Z","shell.execute_reply":"2025-12-26T20:24:51.142886Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/cybersecurity-attack-and-defence-dataset/Attack_Dataset.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\"\"\"\nMulti-Class Classification of Cybersecurity Attacks - Top 15 Analysis\nAuthor: Tayyab Ali (2530-4007)\nDate: December 24, 2025\nDepartment of Cyber Security\n\"\"\"\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import (accuracy_score, precision_score, recall_score, \n                             f1_score, confusion_matrix, classification_report)\ntry:\n    from imblearn.over_sampling import SMOTE\n    SMOTE_AVAILABLE = True\nexcept ImportError:\n    SMOTE_AVAILABLE = False\n    print(\"⚠️ imbalanced-learn not available. Will use class_weight instead.\")\nimport pickle\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set random seed\nnp.random.seed(42)\n\n# ============================================================================\n# 1. DATA LOADING\n# ============================================================================\nprint(\"\\n[STEP 1] Loading Dataset...\")\ndf = pd.read_csv('/kaggle/input/cybersecurity-attack-and-defence-dataset/Attack_Dataset.csv')\n\n# Identify target column\nif 'Attack Type' in df.columns:\n    target_col = 'Attack Type'\nelif 'attack_type' in df.columns:\n    target_col = 'attack_type'\nelse:\n    target_col = df.columns[-1]\n\n# ============================================================================\n# 2. DATA PREPROCESSING (TOP 15 FILTERING)\n# ============================================================================\nprint(\"\\n[STEP 2] Preprocessing Features & Simplifying to Top 15 Attacks...\")\n\n# Remove duplicates\ndf_clean = df.drop_duplicates()\n\n# Separate features and target\nX = df_clean.drop(columns=[target_col])\ny = df_clean[target_col]\n\n# --- KEY CHANGE: KEEP TOP 15 ONLY ---\ntop_15_list = y.value_counts().nlargest(15).index\ny = y.apply(lambda x: x if x in top_15_list else 'Other')\n\nprint(f\"Target filtered to Top 15 + 'Other'. Total classes: {len(y.unique())}\")\nprint(y.value_counts())\n\n# Handle missing values in features (Keeping all features)\nfor col in X.columns:\n    if X[col].isnull().sum() > 0:\n        if X[col].dtype in ['int64', 'float64']:\n            X[col].fillna(X[col].median(), inplace=True)\n        else:\n            X[col].fillna(X[col].mode()[0], inplace=True)\n\n# Encode categorical features\nlabel_encoders = {}\ncategorical_cols = X.select_dtypes(include=['object']).columns\nfor col in categorical_cols:\n    le = LabelEncoder()\n    X[col] = le.fit_transform(X[col].astype(str))\n    label_encoders[col] = le\n\n# Encode target variable\nle_target = LabelEncoder()\ny_encoded = le_target.fit_transform(y)\n\n# Feature Scaling\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Train-Test Split\nX_train, X_test, y_train, y_test = train_test_split(\n    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n)\n\n# Handle Class Imbalance\nif SMOTE_AVAILABLE:\n    smote = SMOTE(random_state=42)\n    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\nelse:\n    X_train_balanced, y_train_balanced = X_train, y_train\n\n# ============================================================================\n# 3. MODEL TRAINING & SAVING\n# ============================================================================\nprint(\"\\n[STEP 3] Training Models...\")\n\nmodels = {\n    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, class_weight='balanced'),\n    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1, class_weight='balanced'),\n    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, eval_metric='mlogloss')\n}\n\nresults = {}\nfor model_name, model in models.items():\n    print(f\"Training: {model_name}...\")\n    model.fit(X_train_balanced, y_train_balanced)\n    y_pred = model.predict(X_test)\n    \n    # Calculate metrics\n    results[model_name] = {'accuracy': accuracy_score(y_test, y_pred), 'predictions': y_pred}\n    \n    # Save Model\n    filename = f'{model_name.replace(\" \", \"_\").lower()}_model.pkl'\n    with open(filename, 'wb') as f:\n        pickle.dump(model, f)\n    print(f\"✓ Saved: {filename}\")\n\n# Save preprocessing objects\nwith open('scaler.pkl', 'wb') as f:\n    pickle.dump(scaler, f)\nwith open('label_encoder_target.pkl', 'wb') as f:\n    pickle.dump(le_target, f)\nwith open('label_encoders.pkl', 'wb') as f:\n    pickle.dump(label_encoders, f)\n\nprint(\"\\n[SUCCESS] Preprocessing files and Top 15 Models are ready!\")\n\n# ============================================================================\n# 4. DOWNLOAD UTILITY (Run this to get the Zip)\n# ============================================================================\nimport shutil\nfrom IPython.display import FileLink\nshutil.make_archive('top15_cybersecurity_models', 'zip', '/kaggle/working/')\nprint(\"\\n--- DOWNLOAD LINK BELOW ---\")\ndisplay(FileLink(r'top15_cybersecurity_models.zip'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-26T20:28:26.089922Z","iopub.execute_input":"2025-12-26T20:28:26.090400Z","iopub.status.idle":"2025-12-26T20:29:46.269585Z","shell.execute_reply.started":"2025-12-26T20:28:26.090371Z","shell.execute_reply":"2025-12-26T20:29:46.268386Z"}},"outputs":[{"name":"stdout","text":"\n[STEP 1] Loading Dataset...\n\n[STEP 2] Preprocessing Features & Simplifying to Top 15 Attacks...\nTarget filtered to Top 15 + 'Other'. Total classes: 16\nAttack Type\nOther                               13090\nHardware Interface Exploitation       161\nWireless Attacks (Advanced)            95\nDependency Confusion                   91\nFuzzer Configuration                   75\nMalicious Libraries                    74\nMalicious Library                      71\nPrivilege Escalation                   61\nRemovable Media Attack                 55\nMisuse of Legitimate Tools             55\nData Exfiltration                      52\nStuxnet-Style PLC Rootkit              52\nDefault Credentials Exploitation       51\nHMI Exploitation                       50\nFirmware Extraction & Analysis         50\nMalicious Peripheral Attack            50\nName: count, dtype: int64\n\n[STEP 3] Training Models...\nTraining: Random Forest...\n✓ Saved: random_forest_model.pkl\nTraining: Logistic Regression...\n✓ Saved: logistic_regression_model.pkl\nTraining: XGBoost...\n✓ Saved: xgboost_model.pkl\n\n[SUCCESS] Preprocessing files and Top 15 Models are ready!\n\n--- DOWNLOAD LINK BELOW ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/top15_cybersecurity_models.zip","text/html":"<a href='top15_cybersecurity_models.zip' target='_blank'>top15_cybersecurity_models.zip</a><br>"},"metadata":{}}],"execution_count":3}]}